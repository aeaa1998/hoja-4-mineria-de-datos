split <- initial_split(barato, prop = .65)
trainBarato <- training(split)
testBarato <- training(split)
# Proporcion 35, 65
train <- bind_rows(trainCaro, trainMedio, trainBarato)
test  <- bind_rows(testCaro, testMedio, testBarato)
fitSpOvCaro<-lm(SalePrice~OverallQual, data = trainMedio)
#Estimar el precio a partir de su calidad en general
predictionCaro<-predict(fitSpOv, newdata = testMedio)
#El analisis de los residuos
# Los residuos se calcula restando la predicción de la variable respuesta
residualesCaro <- testCaro$SalePrice-predictionCaro
fitSpOvCaro<-lm(SalePrice~OverallQual, data = trainMedio)
#Estimar el precio a partir de su calidad en general
predictionCaro<-predict(fitSpOv, newdata = testMedio)
#El analisis de los residuos
# Los residuos se calcula restando la predicción de la variable respuesta
residualesCaro <- testCaro$SalePrice-predictionCaro
#Estimar el precio a partir de su calidad en general
predictionCaro<-predict(fitSpOv, newdata = testMedio)
#El analisis de los residuos
# Los residuos se calcula restando la predicción de la variable respuesta
residualesCaro <- testCaro$SalePrice-predictionCaro
#El analisis de los residuos
# Los residuos se calcula restando la predicción de la variable respuesta
residualesCaro <- testMedio$SalePrice-predictionCaro
#No obstante el modelo ya lo calcula por lo que se pueden usar
# Si se mira el resumen del modelo podemos analizar el comportamiento de los residuos.
summary(fitSpOvCaro)
library(ModelMetrics)
rmse(testMedio$SalePrice,predictionCaro)
test  <- bind_rows(testCaro, testMedio, testBarato)
fitSpOv<-lm(SalePrice~OverallQual, data = train)
#Estimar el precio a partir de su calidad en general
prediction<-predict(fitSpOv, newdata = test)
#El analisis de los residuos
# Los residuos se calcula restando la predicción de la variable respuesta
residualesCaro <- test$SalePrice-prediction
#No obstante el modelo ya lo calcula por lo que se pueden usar
# Si se mira el resumen del modelo podemos analizar el comportamiento de los residuos.
summary(fitSpOvCaro)
library(ModelMetrics)
rmse(test$SalePrice,prediction)
abs(mean(test$SalePrice - prediction))
plot(test$SalePrice, test$OverallQual)
points(predL, test$OverallQual, col="red",pch=15)
par(mfrow = c(2,2))
plot(fitSpOv)
#En la grafica Residuals vs Fitted, se puede ver que los residuos se distribuyen de forma
# mas o menos aleatoria alrededor de 0
# En el grafico qq se puede ver que puede ser un grafico normal
plot(test$SalePrice, test$OverallQual)
points(predL, test$OverallQual, col="red",pch=15)
par(mfrow = c(2,2))
plot(fitSpOv)
#En la grafica Residuals vs Fitted, se puede ver que los residuos se distribuyen de forma
# mas o menos aleatoria alrededor de 0
# En el grafico qq se puede ver que puede ser un grafico normal
plot(test$SalePrice, test$OverallQual)
points(prediction, test$OverallQual, col="red",pch=15)
par(mfrow = c(2,2))
plot(fitSpOv)
residualesCaro
#Podemos ver que queda un valor bastante alto dentro de nuestro RMSE eso es debido a que
#Hay mucha vairacion entre los precios
rmse(test$SalePrice,prediction)
#El analisis de los residuos
# Los residuos se calcula restando la predicción de la variable respuesta
residuales <- test$SalePrice-prediction
summary(residuales)
abs(mean(test$SalePrice - prediction))
#El analisis de los residuos
# Los residuos se calcula restando la predicción de la variable respuesta
residuales <- test$SalePrice-prediction
summary(residuales)
abs(mean(test$SalePrice - prediction))
fitLMP<-lm(SalePrice~. data = train)
fitLMP<-lm(SalePrice~. data = train)
fitLMP<-lm(SalePrice~., data = train)
#caro > 150,000
#barato < 100,000
#medio 100,000 - 150,000
caros = dataSetCompleteNumeric[dataSetCompleteNumeric$SalePrice>150000,]
barato = dataSetCompleteNumeric[dataSetCompleteNumeric$SalePrice<100000,]
medio = dataSetCompleteNumeric[dataSetCompleteNumeric$SalePrice>100000 & dataSetCompleteNumeric$SalePrice<150000,]
#Proporciones caros
split <- initial_split(caros, prop = .65)
trainCaro <- training(split)
testCaro <- training(split)
#Proporciones medios
split <- initial_split(medio, prop = .65)
trainMedio <- training(split)
testMedio <- training(split)
#Proporciones baratos
split <- initial_split(barato, prop = .65)
trainBarato <- training(split)
testBarato <- training(split)
# Proporcion 35, 65
train <- bind_rows(trainCaro, trainMedio, trainBarato)
test  <- bind_rows(testCaro, testMedio, testBarato)
fitSpOv<-lm(SalePrice~OverallQual, data = train)
#Estimar el precio a partir de su calidad en general
prediction<-predict(fitSpOv, newdata = test)
#El analisis de los residuos
# Los residuos se calcula restando la predicción de la variable respuesta
residuales <- test$SalePrice-prediction
summary(residuales)
#No obstante el modelo ya lo calcula por lo que se pueden usar
# Si se mira el resumen del modelo podemos analizar el comportamiento de los residuos.
summary(fitSpOvCaro)
library(ModelMetrics)
#Podemos ver que queda un valor bastante alto dentro de nuestro RMSE eso es debido a que
#Hay mucha vairacion entre los precios
rmse(test$SalePrice,prediction)
print("Mean error de la prediccion y el test")
abs(mean(test$SalePrice - prediction))
#En la grafica Residuals vs Fitted, se puede ver que los residuos se distribuyen de forma
# mas o menos aleatoria alrededor de 0
# En el grafico qq se puede ver que puede ser un grafico normal
plot(test$SalePrice, test$OverallQual)
points(prediction, test$OverallQual, col="red",pch=15)
par(mfrow = c(2,2))
plot(fitSpOv)
fitLMP<-lm(SalePrice~., data = train)
summary(fitLM)
predicted<-predict(fitLM,newdata = test)
fitLMP<-lm(SalePrice~., data = train)
summary(fitLMP)
#No obstante el modelo ya lo calcula por lo que se pueden usar
# Si se mira el resumen del modelo podemos analizar el comportamiento de los residuos.
summary(fitSpOvCaro)
predicted<-predict(fitLMP,newdata = test)
test$prediccion <- predicted
cfm<-confusionMatrix(test$y,test$prediccion)
predicted<-predict(fitLMP,newdata = test)
predicted
cfm<-confusionMatrix(test$y,test$prediccion)
predicted<-predict(fitLMP,newdata = test)
test$prediccion <- predicted
predicted
cfm<-confusionMatrix(test$y,test$prediccion)
cfm<-confusionMatrix(test$SalePrice,test$prediccion)
cfm
#Modelo de Regresi�n lineal
porcentaje<-0.7
datos<-iris
set.seed(123)
datos$y<- as.numeric(datos$Species)
corte <- sample(nrow(datos),nrow(datos)*porcentaje)
train<-datos[corte,]
test<-datos[-corte,]
#-------------------------------------------------
# Regresi�n Lineal Simple
#-------------------------------------------------
fitLMPW<-lm(Petal.Length~Petal.Width, data = train)
#Estimar el lenght del p�talo a partir de su width
#-------
predL<-predict(fitLMPW, newdata = test)
#Verificando la predicci�n
resultados<-data.frame(test$Petal.Length,predL)
#An�lisis de residuos
# Los residuos se calcula restando la predicci�n de la variable respuesta
residuales <- test$Petal.Length-predL
#No obstante el modelo ya lo calcula por lo que se pueden usar
# Si se mira el resumen del modelo podemos analizar el comportamiento de los residuos.
summary(fitLMPW)
#En la gr�fica Residuals vs Fitted, se puede ver que los residuos se distribuyen de forma
# m�s o menos aleatoria alrededor de 0
# En el gr�fico qq se puede ver que puede ser un gr�fico normal
library(ModelMetrics)
rmse(test$Petal.Length,predL)
plot(test$Petal.Length, test$Petal.Width)
points(predL, test$Petal.Width, col="red",pch=15)
par(mfrow = c(2,2))
plot(fitLMPW)
#Predecir la clase de la flor por la longitud del p�talo
fitLMSpByPL<-lm(y~Petal.Length, data = train)
summary(fitLMSpByPL)
# Multiple R-squared:  0.905,	Adjusted R-squared:  0.9041
#El modelo explica los datos en un 90% la predicci�n debe ser buena
predMSpByPL<-predict(fitLMSpByPL,newdata = test)
resultados1<-data.frame(test$y,round(predMSpByPL,0))
names(resultados1)<-c("real","prediccion")
confusionMatrix(resultados1$real,resultados1$prediccion)
#Accuracy : 0.8889
#-------------------------------------------------
# Regresi�n Lineal M�ltiple
#-------------------------------------------------
fitLM<-lm(y~. data = train)
summary(fitLM)
#El modelo se ajusta perfectamente a los datos
#Multiple R-squared:      1,	Adjusted R-squared:      1
#Advertencia que pone R:
# Warning message:
#   In summary.lm(fitLM) : essentially perfect fit: summary may be unreliable
predicted<-predict(fitLM,newdata = test)
test$prediccion <- predicted
cfm<-confusionMatrix(test$y,test$prediccion)
cfm
#Accuracy : 1
#HAY SUBREAJUSTE. Esto se debe a que hay multicolinealidad en las variables participantes en el modelo
cor(datos$Petal.Length,datos$Petal.Width, method = "spearman")
#La correlaci�n es del 93% con Spearman porque las variables no siguen una distrbuci�n normal
#Esta correlaci�n tan fuerte est� interfiriendo en el modelo.
#Quitar la variable Petal.Width
fitLM1<-lm(y ~ Sepal.Length + Petal.Length, data = train)
summary(fitLM1)
# Call:
#   lm(formula = y ~ Sepal.Length + Petal.Length, data = train)
#
# Residuals:
#   Min       1Q   Median       3Q      Max
# -0.61519 -0.17330  0.01859  0.15534  0.53081
#
# Coefficients:
#   Estimate Std. Error t value Pr(>|t|)
# (Intercept)   0.92146    0.26913   3.424  0.00089 ***
#   Sepal.Length -0.13138    0.06094  -2.156  0.03344 *
#   Petal.Length  0.48667    0.02831  17.190  < 2e-16 ***
#   ---
#   Signif. codes:
#   0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#
# Residual standard error: 0.2477 on 102 degrees of freedom
# Multiple R-squared:  0.9092,	Adjusted R-squared:  0.9074
# F-statistic: 510.6 on 2 and 102 DF,  p-value: < 2.2e-16
#Ambos par�metros son significativos por lo que aportan al modelo
#El modelo describe el  90% de los datos por lo que la predicci�n debe ser buena
pred<-predict(fitLM1,newdata = test)
test$prediccionModeloAjustado<-round(pred,0)
cfm1<-confusionMatrix(test$y, test$prediccionModeloAjustado)
#Accuracy : 0.9333
cfm1
cfm
cfm
confussionMatrix<-confusionMatrix(test$SalePrice,test$prediccion)
confussionMatrix
confussionMatrix<-confusionMatrix(test$SalePrice,test$prediccion)
test$prediccion <- predicted
library("ggpubr")
library("ggplot2")
library(dplyr)
library(rpart)
library(caret)
library(tree)
library(rsample)
library(rpart.plot)
library(randomForest)
library(ipred)
trainSetGiven = read.csv("./data/train.csv", header = TRUE)
testSetGiven = read.csv("./data/test.csv", header = TRUE)
#Join the two sets of data
dataSet <- bind_rows(trainSetGiven, testSetGiven)
dataSet$Id=NULL
set.seed(123)
dataSetCompleteNumeric =dataSet[, !sapply(dataSet, is.character)]
dataSetCompleteNumeric = dataSetCompleteNumeric[complete.cases(dataSetCompleteNumeric), ]
dataSet = dataSet[complete.cases(dataSet$SalePrice),]
#caro > 150,000
#barato < 100,000
#medio 100,000 - 150,000
caros = dataSetCompleteNumeric[dataSetCompleteNumeric$SalePrice>150000,]
barato = dataSetCompleteNumeric[dataSetCompleteNumeric$SalePrice<100000,]
medio = dataSetCompleteNumeric[dataSetCompleteNumeric$SalePrice>100000 & dataSetCompleteNumeric$SalePrice<150000,]
#Proporciones caros
split <- initial_split(caros, prop = .65)
trainCaro <- training(split)
testCaro <- training(split)
#Proporciones medios
split <- initial_split(medio, prop = .65)
trainMedio <- training(split)
testMedio <- training(split)
#Proporciones baratos
split <- initial_split(barato, prop = .65)
trainBarato <- training(split)
testBarato <- training(split)
# Proporcion 35, 65
train <- bind_rows(trainCaro, trainMedio, trainBarato)
test  <- bind_rows(testCaro, testMedio, testBarato)
#-------------------------------------------------
# Regresión Lineal Simple
#-------------------------------------------------
#Se escogio Overall Qual ya que con nuestro arbol de regresión se tuvo que esa era
# la vairable mas importante
fitSpOv<-lm(SalePrice~OverallQual, data = train)
#Estimar el precio a partir de su calidad en general
prediction<-predict(fitSpOv, newdata = test)
#El analisis de los residuos
# Los residuos se calcula restando la predicción de la variable respuesta
residuales <- test$SalePrice-prediction
summary(residuales)
#No obstante el modelo ya lo calcula por lo que se pueden usar
# Si se mira el resumen del modelo podemos analizar el comportamiento de los residuos.
summary(fitSpOvCaro)
library(ModelMetrics)
#Podemos ver que queda un valor bastante alto dentro de nuestro RMSE eso es debido a que
#Hay mucha vairacion entre los precios
rmse(test$SalePrice,prediction)
print("Mean error de la prediccion y el test")
abs(mean(test$SalePrice - prediction))
#Podemos ver que en la mediana entre los valores es realmente pequeña lo cual es un buen predictor
#En la grafica Residuals vs Fitted, se puede ver que los residuos se distribuyen de forma
# mas o menos aleatoria alrededor de 0
# En el grafico qq se puede ver que puede ser un grafico normal
plot(test$SalePrice, test$OverallQual)
points(prediction, test$OverallQual, col="red",pch=15)
par(mfrow = c(2,2))
plot(fitSpOv)
#-------------------------------------------------
# Regresion Lineal Multiple
#-------------------------------------------------
fitLMP<-lm(SalePrice~., data = train)
summary(fitLMP)
#El modelo ajusta bastante bien
#Multiple R-squared:      0.81,	Adjusted R-squared:      0.80
predicted<-predict(fitLMP,newdata = test)
test$prediccion <- predicted
predicted
confussionMatrix<-confusionMatrix(test$SalePrice,test$prediccion)
confussionMatrix
#Accuracy : 1
#HAY SUBREAJUSTE. Esto se debe a que hay multicolinealidad en las variables participantes en el modelo
cor(datos$Petal.Length,datos$Petal.Width, method = "spearman")
#La correlaci�n es del 93% con Spearman porque las variables no siguen una distrbuci�n normal
#Esta correlaci�n tan fuerte est� interfiriendo en el modelo.
#Quitar la variable Petal.Width
fitLM1<-lm(y ~ Sepal.Length + Petal.Length, data = train)
summary(fitLM1)
# Call:
#   lm(formula = y ~ Sepal.Length + Petal.Length, data = train)
#
# Residuals:
#   Min       1Q   Median       3Q      Max
# -0.61519 -0.17330  0.01859  0.15534  0.53081
#
# Coefficients:
#   Estimate Std. Error t value Pr(>|t|)
# (Intercept)   0.92146    0.26913   3.424  0.00089 ***
#   Sepal.Length -0.13138    0.06094  -2.156  0.03344 *
#   Petal.Length  0.48667    0.02831  17.190  < 2e-16 ***
#   ---
#   Signif. codes:
#   0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#
# Residual standard error: 0.2477 on 102 degrees of freedom
# Multiple R-squared:  0.9092,	Adjusted R-squared:  0.9074
# F-statistic: 510.6 on 2 and 102 DF,  p-value: < 2.2e-16
#Ambos par�metros son significativos por lo que aportan al modelo
#El modelo describe el  90% de los datos por lo que la predicci�n debe ser buena
pred<-predict(fitLM1,newdata = test)
test$prediccionModeloAjustado<-round(pred,0)
cfm1<-confusionMatrix(test$y, test$prediccionModeloAjustado)
#Accuracy : 0.9333
predicted<-predict(fitLMP,newdata = test)
test$prediccion <- predicted
predicted
confussionMatrix<-confusionMatrix(test$SalePrice,test$prediccion)
confussionMatrix
predicted
trainSetGiven = read.csv("./data/train.csv", header = TRUE)
#Join the two sets of data
dataSet <- bind_rows(trainSetGiven)
dataSet$Id=NULL
set.seed(123)
dataSetCompleteNumeric =dataSet[, !sapply(dataSet, is.character)]
dataSetCompleteNumeric = dataSetCompleteNumeric[complete.cases(dataSetCompleteNumeric), ]
dataSet = dataSet[complete.cases(dataSet$SalePrice),]
#caro > 150,000
#barato < 100,000
#medio 100,000 - 150,000
caros = dataSetCompleteNumeric[dataSetCompleteNumeric$SalePrice>150000,]
barato = dataSetCompleteNumeric[dataSetCompleteNumeric$SalePrice<100000,]
medio = dataSetCompleteNumeric[dataSetCompleteNumeric$SalePrice>100000 & dataSetCompleteNumeric$SalePrice<150000,]
#Proporciones caros
split <- initial_split(caros, prop = .65)
trainCaro <- training(split)
testCaro <- training(split)
#Proporciones medios
split <- initial_split(medio, prop = .65)
trainMedio <- training(split)
testMedio <- training(split)
#Proporciones baratos
split <- initial_split(barato, prop = .65)
trainBarato <- training(split)
testBarato <- training(split)
# Proporcion 35, 65
train <- bind_rows(trainCaro, trainMedio, trainBarato)
test  <- bind_rows(testCaro, testMedio, testBarato)
fitSpOv<-lm(SalePrice~OverallQual, data = train)
#Estimar el precio a partir de su calidad en general
prediction<-predict(fitSpOv, newdata = test)
residuales <- test$SalePrice-prediction
summary(residuales)
print("Mean error de la prediccion y el test")
abs(mean(test$SalePrice - prediction))
#No obstante el modelo ya lo calcula por lo que se pueden usar
# Si se mira el resumen del modelo podemos analizar el comportamiento de los residuos.
summary(fitSpOvCaro)
library(ModelMetrics)
#Podemos ver que queda un valor bastante alto dentro de nuestro RMSE eso es debido a que
#Hay mucha vairacion entre los precios
rmse(test$SalePrice,prediction)
#En la grafica Residuals vs Fitted, se puede ver que los residuos se distribuyen de forma
# mas o menos aleatoria alrededor de 0
# En el grafico qq se puede ver que puede ser un grafico normal
plot(test$SalePrice, test$OverallQual)
points(prediction, test$OverallQual, col="red",pch=15)
par(mfrow = c(2,2))
plot(fitSpOv)
fitLMP<-lm(SalePrice~., data = train)
summary(fitLMP)
predicted<-predict(fitLMP,newdata = test)
test$prediccion <- predicted
predicted
confussionMatrix<-confusionMatrix(test$SalePrice,test$prediccion)
confussionMatrix
abs(mean(test$SalePrice - prediction))
summary(residuales)
residuales
print("Mean error de la prediccion y el test")
abs(mean(test$SalePrice - prediction))
library(corrplot)
library(corrplot)
summary(fitLMP)
library(corrplot)
predicted<-predict(fitLMP,newdata = test)
test$prediccion <- predicted
predicted
confussionMatrix<-confusionMatrix(test$SalePrice,test$prediccion)
#Get the correlation plot
par(mfrow = c(1,1))
corrplot(cor(data))
corrplot(cor(test))
corrplot(cor(dataSetCompleteNumeric))
summary(fitLMP)
#Set new model with only important variables
train$LotFrontage = NULL
train$LotArea = NULL
train$LotArea = NULL
train$YearRemodAdd = NULL
train$BsmtFinSF1 = NULL
train$BsmtFinSF2 = NULL
train$BsmtUnfSF = NULL
train$TotalBsmtSF = NULL
train$LowQualFinSF = NULL
train$GrLivArea = NULL
train$BsmtHalfBath = NULL
train$FullBath = NULL
train$HalfBath = NULL
train$GarageYrBlt = NULL
train$GarageArea = NULL
train$WoodDeckSF = NULL
train$OpenPorchSF = NULL
train$EnclosedPorch = NULL
train$X3SsnPorch = NULL
train$PoolArea = NULL
train$MiscVal = NULL
train$MoSold = NULL
train$YrSold = NULL
rmse(test$SalePrice,test$prediccion)
#Analisis de residuales con todas las variables
residuales <- test$SalePrice-test$prediccion
summary(residuales)
print("Mean error de la prediccion y el test con todas las variab;es")
abs(mean(test$SalePrice - prediction))
plot(test$SalePrice, test$OverallQual)
points(prediction, test$OverallQual, col="red",pch=15)
par(mfrow = c(2,2))
plot(fitLMP)
fitCheckOV<-lm(SalePrice~., data = train)
summary(fitCheckOV)
summary(fitCheckOV)
#Get the correlation plot
par(mfrow = c(1,1))
corrplot(cor(train))
train$YearBuilt = NULL
train$X1stFlrSF = NULL
train$GarageCars = NULL
train$TotRmsAbvGrd = NULL
#Modelo sin overfitting
fitCheckNoOverfitting<-lm(SalePrice~., data = train)
summary(fitCheckNoOverfitting)
par(mfrow = c(1,1))
corrplot(cor(train))
#Modelo sin overfitting
train$OverallCond = NULL
train$KitchenAbvGr = NULL
fitCheckNoOverfitting<-lm(SalePrice~., data = train)
summary(fitCheckNoOverfitting)
par(mfrow = c(1,1))
corrplot(cor(train))
#Modelo sin overfitting
train$OverallCond = NULL
train$KitchenAbvGr = NULL
train$BedroomAbvGr = NULL
fitCheckNoOverfitting<-lm(SalePrice~., data = train)
summary(fitCheckNoOverfitting)
predicted<-predict(fitCheckNoOverfitting,newdata = test)
test$new_prediccion <- predicted
rmse(test$SalePrice,test$new_prediccion)
#Analisis de residuales con todas las variables
residuales <- test$SalePrice-test$prediccion
#Analisis de residuales con todas las variables
residuales <- test$SalePrice-test$new_prediccion
summary(residuales)
print("Mean error de la prediccion y el test con todas las variables")
abs(mean(test$SalePrice - prediction))
print("Nos queda un error bastante bajo en los residuales dando tambien un buen modelo")
plot(test$SalePrice, test$OverallQual)
points(prediction, test$OverallQual, col="red",pch=15)
par(mfrow = c(2,2))
plot(fitLMP)
